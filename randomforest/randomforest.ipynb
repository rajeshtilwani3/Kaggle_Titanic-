{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80898876  0.82022472  0.83146067  0.80898876  0.79775281  0.76404494\n",
      "  0.82022472  0.87640449]\n",
      "0.816011235955\n",
      "0.824438202247\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from sklearn.preprocessing import Imputer \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "df = pd.read_csv(\"train.csv\") \n",
    "X_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "df['Title'] = df['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "# a map of more aggregated titles\n",
    "Title_Dictionary = {\n",
    "                        \"Capt\":       \"Officer\",\n",
    "                        \"Col\":        \"Officer\",\n",
    "                        \"Major\":      \"Officer\",\n",
    "                        \"Jonkheer\":   \"Royalty\",\n",
    "                        \"Don\":        \"Royalty\",\n",
    "                        \"Sir\" :       \"Royalty\",\n",
    "                        \"Dr\":         \"Officer\",\n",
    "                        \"Rev\":        \"Officer\",\n",
    "                        \"the Countess\":\"Royalty\",\n",
    "                        \"Dona\":       \"Royalty\",\n",
    "                        \"Mme\":        \"Mrs\",\n",
    "                        \"Mlle\":       \"Miss\",\n",
    "                        \"Ms\":         \"Mrs\",\n",
    "                        \"Mr\" :        \"Mr\",\n",
    "                        \"Mrs\" :       \"Mrs\",\n",
    "                        \"Miss\" :      \"Miss\",\n",
    "                        \"Master\" :    \"Master\",\n",
    "                        \"Lady\" :      \"Royalty\"\n",
    "\n",
    "                        }\n",
    "    \n",
    "# we map each title\n",
    "df['Title'] = df.Title.map(Title_Dictionary)\n",
    "\n",
    "X_test = pd.read_csv(\"test.csv\")\n",
    "X_test['Title'] = X_test['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())   \n",
    "# we map each title\n",
    "X_test['Title'] = X_test.Title.map(Title_Dictionary)\n",
    "\n",
    "\n",
    "# encoding in dummy variable\n",
    "titles_dummies = pd.get_dummies(df['Title'],prefix='Title')\n",
    "df = pd.concat([df,titles_dummies],axis=1)\n",
    "    \n",
    "# removing the title variable\n",
    "df.drop('Title',axis=1,inplace=True)\n",
    "\n",
    "# encoding in dummy variable\n",
    "titles_dummies = pd.get_dummies(X_test['Title'],prefix='Title')\n",
    "X_test = pd.concat([X_test,titles_dummies],axis=1)\n",
    "    \n",
    "# removing the title variable\n",
    "X_test.drop('Title',axis=1,inplace=True)\n",
    "\n",
    "df = df.drop(['Ticket', 'Cabin', 'Name', 'Fare','PassengerId'],axis=1)\n",
    "df = df.dropna()\n",
    "y = df[\"Survived\"]\n",
    "X = df.drop(\"Survived\", axis=1)\n",
    "\n",
    "X_test = X_test.drop(['Ticket', 'Cabin', 'Name', 'Fare','PassengerId'],axis=1)\n",
    "\n",
    "# sex and embarrked are object so we convert them to categorical data and then to numerical data using one hot encoding \n",
    "# 1. INSTANTIATE\n",
    "# encode labels with value between 0 and n_classes-1.\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# X_test['Sex']=le.fit_transform(X_test.__getattr__('Sex'))\n",
    "# X_test['Embarked']=le.fit_transform(X_test.__getattr__('Embarked'))\n",
    "\n",
    "# X['Sex']=le.fit_transform(X.__getattr__('Sex'))\n",
    "# X['Embarked']=le.fit_transform(X.__getattr__('Embarked'))\n",
    "# X = X.apply(le.fit_transform)\n",
    "X[\"male\"]= np.where(X['Sex']==\"male\", 1, 0)\n",
    "X[\"female\"]= np.where(X['Sex']==\"female\", 1, 0)\n",
    "X[\"S\"]= np.where(X['Embarked']==\"S\", 1, 0)\n",
    "X[\"C\"]= np.where(X['Embarked']==\"C\", 1, 0)\n",
    "X[\"Q\"]= np.where(X['Embarked']==\"Q\", 1, 0)\n",
    "X[\"First\"]= np.where(X['Pclass']==1, 1, 0)\n",
    "X[\"Second\"]= np.where(X['Pclass']==2, 1, 0)\n",
    "X[\"Third\"]= np.where(X['Pclass']==3, 1, 0)\n",
    "\n",
    "X = X.drop('Pclass',axis=1)\n",
    "\n",
    "X_test[\"male\"]= np.where(X_test['Sex']==\"male\", 1, 0)\n",
    "X_test[\"female\"]= np.where(X_test['Sex']==\"female\", 1, 0)\n",
    "X_test[\"S\"]= np.where(X_test['Embarked']==\"S\", 1, 0)\n",
    "X_test[\"C\"]= np.where(X_test['Embarked']==\"C\", 1, 0)\n",
    "X_test[\"Q\"]= np.where(X_test['Embarked']==\"Q\", 1, 0)\n",
    "X_test[\"First\"]= np.where(X_test['Pclass']==1, 1, 0)\n",
    "X_test[\"Second\"]= np.where(X_test['Pclass']==2, 1, 0)\n",
    "X_test[\"Third\"]= np.where(X_test['Pclass']==3, 1, 0)\n",
    "\n",
    "X_test = X_test.drop('Pclass',axis=1)\n",
    "X = X.drop(\"Embarked\", axis=1)\n",
    "X = X.drop(\"Sex\", axis=1)\n",
    "X_test = X_test.drop(\"Embarked\", axis=1)\n",
    "X_test = X_test.drop(\"Sex\", axis=1)\n",
    "\n",
    "scaler = MinMaxScaler() \n",
    "scaled_values = scaler.fit_transform(X) \n",
    "X.loc[:,:] = scaled_values\n",
    "X\n",
    "\n",
    "my_imputer = Imputer()\n",
    "X_test = my_imputer.fit_transform(X_test)\n",
    "X_test= scaler.transform(X_test)\n",
    "X_test\n",
    "model = RandomForestClassifier(n_estimators=100, max_features =7, max_depth=3, random_state=3)\n",
    "# model.fit(X,y)\n",
    "# model.score(X,y)\n",
    "# result = model.predict(X_test)\n",
    "# pd.Series(result).to_csv('svc_rbf_normalized_gamma_c.csv')\n",
    "cv_scores = cross_val_score(model, X, y, cv=8)\n",
    "print(cv_scores)\n",
    "print(np.mean(cv_scores))\n",
    "\n",
    "# tried with logistic regression till now without one hot encoding. Trying with one hot encoding now \n",
    "\n",
    "# TODO: create a OneHotEncoder object, and fit it to all of X\n",
    "# 1. INSTANTIATE\n",
    "# enc = preprocessing.OneHotEncoder()\n",
    "# # # 2. FIT\n",
    "# enc.fit(X)\n",
    "# # 3. Transform\n",
    "# X = enc.transform(X)\n",
    "# model = LogisticRegression()\n",
    "model.fit(X,y)\n",
    "score = model.score(X, y)\n",
    "print(score)\n",
    "result = model.predict(X_test)\n",
    "pd.Series(result).to_csv('randomforest2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
